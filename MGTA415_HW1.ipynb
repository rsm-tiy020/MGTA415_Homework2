{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'FPB.csv'\n",
    "data = pd.read_csv(file_path, header = None, encoding='ISO-8859-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_stem_remove_stopwords_punct(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words and token not in string.punctuation]\n",
    "    return stemmed_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [accord, gran, compani, plan, move, product, r...\n",
       "1    [technopoli, plan, develop, stage, area, less,...\n",
       "2    [the, intern, electron, industri, compani, elc...\n",
       "3    [with, new, product, plant, compani, would, in...\n",
       "4    [accord, compani, 's, updat, strategi, year, 2...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_five_processed = data.iloc[:5, 1].apply(tokenize_stem_remove_stopwords_punct)\n",
    "\n",
    "first_five_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = data.iloc[:, 0]\n",
    "text = data.iloc[:, 1]\n",
    "\n",
    "# Splitting the data into training, validation, and test sets (80/10/10 split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(text, labels, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Binary representation\n",
    "vectorizer_binary = CountVectorizer(binary=True)\n",
    "X_train_binary = vectorizer_binary.fit_transform(X_train)\n",
    "X_test_binary = vectorizer_binary.transform(X_test)\n",
    "\n",
    "# Frequency-based representation\n",
    "vectorizer_freq = CountVectorizer(binary=False)\n",
    "X_train_freq = vectorizer_freq.fit_transform(X_train)\n",
    "X_test_freq = vectorizer_freq.transform(X_test)\n",
    "\n",
    "# TF-IDF representation\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_binary, y_train)\n",
    "\n",
    "# Predictions for evaluation\n",
    "predictions = model.predict(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels for multi-class AUROC calculation\n",
    "y_test_binarized = label_binarize(y_test, classes=sorted(y_train.unique()))\n",
    "y_score = model.predict_proba(X_test_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Model - AUROC (OvR): 0.898840980468315, Macro F1: 0.7323926837008293, Micro F1: 0.7731958762886598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Binary Model\n",
    "model_binary = LogisticRegression()\n",
    "model_binary.fit(X_train_binary, y_train)\n",
    "predictions_binary = model_binary.predict(X_test_binary)\n",
    "y_score_binary = model_binary.predict_proba(X_test_binary)\n",
    "\n",
    "# Evaluation\n",
    "auc_binary = roc_auc_score(y_test_binarized, y_score_binary, multi_class='ovr')\n",
    "f1_macro_binary = f1_score(y_test, predictions_binary, average='macro')\n",
    "f1_micro_binary = f1_score(y_test, predictions_binary, average='micro')\n",
    "\n",
    "print(f\"Binary Model - AUROC (OvR): {auc_binary}, Macro F1: {f1_macro_binary}, Micro F1: {f1_micro_binary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency-Based Model - AUROC (OvR): 0.8952190729788353, Macro F1: 0.7378383218454935, Micro F1: 0.777319587628866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Frequency-Based Model\n",
    "model_freq = LogisticRegression()\n",
    "model_freq.fit(X_train_freq, y_train)\n",
    "predictions_freq = model_freq.predict(X_test_freq)\n",
    "y_score_freq = model_freq.predict_proba(X_test_freq)\n",
    "\n",
    "# Evaluation\n",
    "auc_freq = roc_auc_score(y_test_binarized, y_score_freq, multi_class='ovr')\n",
    "f1_macro_freq = f1_score(y_test, predictions_freq, average='macro')\n",
    "f1_micro_freq = f1_score(y_test, predictions_freq, average='micro')\n",
    "\n",
    "print(f\"Frequency-Based Model - AUROC (OvR): {auc_freq}, Macro F1: {f1_macro_freq}, Micro F1: {f1_micro_freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Model - AUROC (OvR): 0.8993878326289192, Macro F1: 0.7208026136171498, Micro F1: 0.777319587628866\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Model\n",
    "model_tfidf = LogisticRegression()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "predictions_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "y_score_tfidf = model_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "auc_tfidf = roc_auc_score(y_test_binarized, y_score_tfidf, multi_class='ovr')\n",
    "f1_macro_tfidf = f1_score(y_test, predictions_tfidf, average='macro')\n",
    "f1_micro_tfidf = f1_score(y_test, predictions_tfidf, average='micro')\n",
    "\n",
    "print(f\"TF-IDF Model - AUROC (OvR): {auc_tfidf}, Macro F1: {f1_macro_tfidf}, Micro F1: {f1_micro_tfidf}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
